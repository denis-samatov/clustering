# Кластеризация методом K-Means

## Что это такое?
K-Means - один из самых популярных методов кластеризации. Он разбивает набор данных на заранее заданное количество кластеров (K), минимизируя среднеквадратичное расстояние между точками и их центроидами.

## Принцип работы
Алгоритм начинается с произвольного выбора центроидов для кластеров. Затем каждая точка данных присваивается ближайшему центроиду, и центроиды пересчитываются как среднее положение точек в каждом кластере. Этот процесс повторяется до сходимости.

## Особенности:
1. Чувствителен к выбору начальных центроидов, что может повлиять на итоговую кластеризацию.
2. Подходит для данных с четко выраженными кластерами, но может давать плохие результаты для неоднородных или перекрывающихся кластеров.

## Пример:
```python
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

# Создание искусственных данных
X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)

# Применение метода K-Means
kmeans = KMeans(n_clusters=4)
kmeans.fit(X)

# Визуализация кластеров
plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_, cmap='viridis')
centers = kmeans.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.75)
plt.show()
```

## Результат:

![Пример изображения](example.png)

# Иерархическая кластеризация

## Что это такое?
Этот метод строит иерархию кластеров, представляющую собой дерево (дендрограмму), где каждый узел соответствует кластеру.

## Принцип работы
Начинается с того, что каждая точка данных представляет собой отдельный кластер, затем на каждом шаге ближайшие кластеры объединяются до тех пор, пока все точки не будут представлены в одном кластере.

## Особенности:
1. Позволяет создавать дендрограммы, которые визуально отображают структуру данных и позволяют выбирать оптимальное количество кластеров.
2. Может быть агломеративным (объединяющим) или дивизивным (разделяющим) в зависимости от подхода.

## Пример:
```python
from scipy.cluster.hierarchy import dendrogram, linkage
import numpy as np
import matplotlib.pyplot as plt

# Генерация случайных данных
np.random.seed(0)
X = np.random.rand(10, 2)

# Иерархическая кластеризация
linked = linkage(X, 'single')

# Построение дендрограммы
dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)
plt.title('Иерархическая кластеризация')
plt.xlabel('Индекс образца')
plt.ylabel('Расстояние')
plt.show()
```

## Результат:

![Пример изображения](example.png)

# Кластеризация методом DBSCAN

## Что это такое?
DBSCAN основан на плотности данных. Он идентифицирует кластеры как области высокой плотности, разделенные областями низкой плотности.

## Принцип работы
Алгоритм начинает с случайной точки и ищет соседей внутри заданного радиуса. Если точка содержит достаточное количество соседей, она становится частью кластера. Процесс распространяется от точки к точке до тех пор, пока все точки не будут посещены.

## Особенности:
1. Может обрабатывать кластеры произвольной формы и обнаруживать выбросы (шум).
2. Не требует заранее указанного числа кластеров, но имеет параметры, такие как радиус эпсилон (eps) и минимальное количество точек в кластере (min_samples).

## Пример:
```python
from sklearn.cluster import DBSCAN
from sklearn.datasets import make_moons
import matplotlib.pyplot as plt

# Создание искусственных данных
X, _ = make_moons(n_samples=200, shuffle=True, noise=0.1)

# Применение метода K-Means
kmeans = KMeans(n_clusters=2)
kmeans.fit(X)
clusters = kmeans.predict(X)

# Визуализация кластеров
plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis')
plt.show()

# Применение метода DBSCAN
dbscan = DBSCAN(eps=0.3, min_samples=10)
clusters = dbscan.fit_predict(X)

# Визуализация кластеров
plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis')
plt.show()
```

## Результат:

![Пример изображения](example.png)
